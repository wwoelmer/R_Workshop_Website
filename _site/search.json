[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R_Workshops_Website",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "These tutorials were made by Whitney Woelmer and James Dare as a collaboration between the University of Waikato and the Bay of Plenty Regional Council. They are intended to provide an introductory understanding in using RStudio for manipulating, visualizing, and analyzing environmental data.\nThe tutorials are provided for free and available to use by any.\nPlease contact Whitney at wwoelmer[at]waikato.ac.nz or James at james.dare[at]boprc.govt.nz with any questions."
  },
  {
    "objectID": "Lesson5.html",
    "href": "Lesson5.html",
    "title": "Lesson 5: Statistical Analysis in R",
    "section": "",
    "text": "Lesson 5: Statistical analyses in R"
  },
  {
    "objectID": "workshops/R_Tutorial_5_2025.html",
    "href": "workshops/R_Tutorial_5_2025.html",
    "title": "BOPRC R Tutorial 5 - Statistical Analyses in R",
    "section": "",
    "text": "This lesson is designed to provide you with experience in running statistical analyses in R. We will use water quality data as an example, but these analyses can be applied to many other datasets, provided the statistical assumptions are met. We will cover the following topics:\n\nCorrelation analyses (Pearson and Spearman) and plots\nLinear regression and plots\nT-tests and Wilcoxon rank sum test (aka Mann-Whitney)\nANOVA\n\n\n\n\n\n\n\nNote\n\n\n\nDisclaimer\nThis lesson teaches the implementation of multiple statistical analyses, rather than the background behind why, when, and what to check when choosing a statistical analysis. You should always check the underlying assumptions of an analysis and whether your data meet those assumptions.\n\n\nWe are adding a few new packages today which perform specialized functions for statistical analyses. You don’t need to worry about the new packages too much, other than you will need to install and load the libraries.\nThe main packages that we will use in this tutorial are:\n\ntidyverse\nlubridate\nHmisc\ncorrplot\nggpmisc\nggpubr\n\nBefore attempting to install these packages, make sure your Primary CRAN Repository is set to:\n\n“New Zealand [https] - University of Auckland”\n\nTo check this, click ‘Tools’ –&gt; ‘Global Options’ –&gt; ‘Packages’. Click ‘Change’ if you need to adjust this.\nYou can download most packages by clicking on the ‘Install’ button on the ‘packages’ tab in the lower right window pane. Then in the Install Packages popup, select ‘Repository (CRAN)’ from the ‘Install from’ drop box and type the name of the package you wish to download (e.g., dplyr).\nOnce all of these packages are installed you can load them using the library function:\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(Hmisc)\nlibrary(corrplot)\nlibrary(ggpmisc)\n\nWarning: package 'ggpmisc' was built under R version 4.4.3\n\n\nWarning: package 'ggpp' was built under R version 4.4.3\n\nlibrary(ggpubr)\n\nFirst we will load in our data. We will use the same water quality data from Lesson 3. This data has been downloaded from Aquarius using the R script which you can find at scripts/download_data_aquarius.R if you’d like to see how the data were downloaded. For today, we are skipping that step and reading in directly from a .csv file which was written after the Aquarius download.\n\nwq &lt;- read.csv('./data/Lake_WQ_Timeseries.csv')\n\nNow, look at the wq dataframe by clicking on it in the environment and familiarise yourself with the columns. You can also run the function colnames(wq) in the console to get a list of column names. It’s better to run this in the console (rather than in your script editor), since it is a diagnostic test and not something you will necessary need to run every time you open your script–just as needed.\n\ncolnames(wq) # you don't have to save this in your script, but can copy it into the console\n\n [1] \"Site\"                \"LocationName\"        \"Time\"               \n [4] \"Value\"               \"Quality\"             \"Approval\"           \n [7] \"Qualifiers\"          \"Parameter\"           \"Unit\"               \n[10] \"Sample_Number\"       \"Project_Id\"          \"LowerDetectionLimit\"\n[13] \"UpperDetectionLimit\" \"Method\"              \"CollectionMethod\"   \n[16] \"Lab\"                 \"Error\"               \"Comment\"            \n[19] \"ACTION\"              \"Samp_Comment\"        \"Cloud_Cover\"        \n[22] \"Num_Swimmers\"        \"Tide_Cycle\"          \"Tide\"               \n[25] \"Wind_Direction\"      \"Wind_Speed\"          \"Weather_Today\"      \n[28] \"Weather_Yest\"        \"Surface_Cond\"        \"Bore_Type\"          \n[31] \"Bore_Number\"         \"Bore_Collect_Method\" \"Bore_Sampled_From\"  \n[34] \"Bore_Pump_Rate\"      \"Bore_Pump_Duration\"  \"Bore_Protocol\"      \n[37] \"Bore_Probe\"          \"Odour\"              \n\n\nAs we know from previous lessons, it is always best practice is to format date/time objects with the appropriate timezone, otherwise R will assume a timezone, and that can lead to the wrong date being set for your timestamp. This is the first thing I do when I see I have a datetime object as a column. Let’s use a bit of code that will parse our Time column, which includes both a date and a time.\nHere, we will use a function called parse_date_time which looks at the Time column, and then provides a list (using c()) of potential formats that the column will be in. Here, we list two formats, the first one has YMD and HMS (hours, minutes, seconds), the second one just has YMD, as some of the values in the Time column don’t have an associated time next to the date. We pair this with the mutate function to re-write our Time column.\nNOTE: there are many ways to format/parse dates and times in R. This is just one example!\n\nwq &lt;- wq %&gt;% mutate(Time = parse_date_time(Time,c(\"%Y-%m-%d %H:%M:%S\",\"%Y-%m-%d\"), tz = \"etc/GMT+12\"))\n\n\nChallenge 1: What locations and parameters are included in this dataset? Use the unique() function to find out.\n\n\nClick to see a solution\n\n\nunique(wq$Parameter)\n\n[1] \"TN (g/m^3)\"    \"TP (g/m^3)\"    \"CHLA (mg/m^3)\" \"VC - SD (m)\"  \n\nunique(wq$LocationName)\n\n [1] \"Lake Rotoma at Site 1 (Integrated)\"       \n [2] \"Lake Rotoehu at Site 3 (Integrated)\"      \n [3] \"Lake Rotoiti at Site 4 (Integrated)\"      \n [4] \"Lake Rotoiti at Site 3 (Integrated)\"      \n [5] \"Lake Rotoiti at Okawa Bay (Integrated)\"   \n [6] \"Lake Rotorua at Site 2 (Integrated)\"      \n [7] \"Lake Okataina at Site 1 (Integrated)\"     \n [8] \"Lake Okareka at Site 1 (Integrated)\"      \n [9] \"Lake Tikitapu at Site 1 (Integrated)\"     \n[10] \"Lake Rerewhakaaitu at Site 1 (Integrated)\"\n[11] \"Lake Okaro at Site 1 (Integrated)\"        \n[12] \"Lake Rotorua at Site 5 (Integrated)\"      \n[13] \"Lake Tarawera at Site 5 (Integrated)\"     \n[14] \"Lake Rotomahana at Site 2 (Integrated)\"   \n\n\n\n\nThat helps us get a better understanding of the dataset that we’re working with and is something I will do often while working in R to remind myself.\nSince we are going to do correlation analysis first, let’s focus on just one site and look at the relationships between variables in the Parameter column. We will filter the data to only select “Lake Okaro at Site 1 (Integrated)” and we will create a new dataframe named wq_okaro so we keep all the other lake data in the wq dataframe.\n\nwq_okaro &lt;- wq %&gt;% \n  filter(LocationName=='Lake Okaro at Site 1 (Integrated)')\n\nLet’s also clean up the dataframe and only select the columns which are useful to us right now\n\nwq_okaro &lt;- wq_okaro %&gt;% \n  select(Time, Value, Parameter, Unit)\n\nLet’s plot the data to make sure everything looks good. I like to do a geom_point plot, as well as a histogram, using geom_histogram\n\nggplot(wq_okaro, aes(x = as.POSIXct(Time), y = Value, color = Parameter)) +\n  geom_point() +\n  facet_wrap(~Parameter, scales = 'free') +\n  theme_bw() +\n  xlab('Time')\n\n\n\n\n\n\n\nggplot(wq_okaro, aes(x = Value, fill = Parameter)) +\n  geom_histogram() +\n  facet_wrap(~Parameter, scales = 'free') +\n  theme_bw()\n\n\n\n\n\n\n\n\nAlright, we have a time series of four variables. There are many things we can do to analyse this data. Let’s start with a correlation analysis."
  },
  {
    "objectID": "workshops/R_Tutorial_5_2025.html#disclaimer",
    "href": "workshops/R_Tutorial_5_2025.html#disclaimer",
    "title": "BOPRC R Tutorial 5 - Statistical Analyses in R",
    "section": "",
    "text": "This lesson teaches the implementation of multiple statistical analyses, rather than the background behind why, when, and what to check when choosing a statistical analysis. You should always check the underlying assumptions of an analysis and whether your data meet those assumptions.\nWe are adding a few new packages today which perform specialized functions for statistical analyses. You don’t need to worry about the new packages too much, other than you will need to install and load the libraries."
  },
  {
    "objectID": "workshops/R_Tutorial_5_2025.html#t-test",
    "href": "workshops/R_Tutorial_5_2025.html#t-test",
    "title": "BOPRC R Tutorial 5 - Statistical Analyses in R",
    "section": "4.1 T-test",
    "text": "4.1 T-test\nLet’s also create a boxplot which will show the distributions of data at each site. We will need to pivot_longer again to show the boxplots with the sites on the x-axis, so we will do this in the tidyverse pipe style, without creating a new object.\n\nt.test(log(rotoiti_wide$OkawaBay_chla), log(rotoiti_wide$Site4_chla), paired = TRUE)\n\n\n    Paired t-test\n\ndata:  log(rotoiti_wide$OkawaBay_chla) and log(rotoiti_wide$Site4_chla)\nt = 8.5839, df = 65, p-value = 2.689e-12\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.6182031 0.9930897\nsample estimates:\nmean difference \n      0.8056464 \n\nrotoiti_wide %&gt;%\n    pivot_longer(OkawaBay_chla:Site4_chla, names_to = \"Site\", values_to = \"Chla\") %&gt;%\n    ggplot(aes(x = Site, y = log(Chla), fill = Site)) + geom_boxplot() + theme_bw() +\n    ylab(\"Log Chl-a\") + stat_compare_means(method = \"t.test\", label = \"p.format\")\n\nWarning: Removed 92 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 92 rows containing non-finite outside the scale range\n(`stat_compare_means()`).\n\n\n\n\n\n\n\n\n\nThe results of our t-test show that these two sites are significantly different from each other. This isn’t too surprising given that Okawa Bay is a much shallower, isolated bay on the western end of Lake Rotoiti, while Site 4 is located in the much deeper main basin. Visually inspecting the boxplots also supports this. Cool!"
  },
  {
    "objectID": "workshops/R_Tutorial_5_2025.html#wilcoxon-rank-sum",
    "href": "workshops/R_Tutorial_5_2025.html#wilcoxon-rank-sum",
    "title": "BOPRC R Tutorial 5 - Statistical Analyses in R",
    "section": "4.2 Wilcoxon rank sum",
    "text": "4.2 Wilcoxon rank sum\nNow, let’s say we didn’t want to log-transform our data. We can use non-parametric statistical tests to look for differences between non-normally distributed datasets. We will use the Wilcoxon rank sum test for this (sometimes called the Mann-Whitney test).\nLet’s run the test using the wilcoxon.test function, and also create our boxplot figure. We will use the argument paired = TRUE in our Wilcoxon test because these samples were taken at roughly the same time and are expected to be representative of similar conditions at both sites.\n\nwilcox.test(rotoiti_wide$OkawaBay_chla, rotoiti_wide$Site4_chla, paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  rotoiti_wide$OkawaBay_chla and rotoiti_wide$Site4_chla\nV = 2046.5, p-value = 1.877e-09\nalternative hypothesis: true location shift is not equal to 0\n\nrotoiti_wide %&gt;%\n    pivot_longer(OkawaBay_chla:Site4_chla, names_to = \"Site\", values_to = \"Chla\") %&gt;%\n    ggplot(aes(x = Site, y = Chla, fill = Site)) + geom_boxplot() + theme_bw() +\n    stat_compare_means(method = \"wilcox.test\", label = \"p.format\")\n\nWarning: Removed 92 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 92 rows containing non-finite outside the scale range\n(`stat_compare_means()`).\n\n\n\n\n\n\n\n\n\nWith the Wilcoxon rank sum test on our raw data, we also show that there is a statistical difference between these two sites. Pretty cool to see that two locations within the same lake are significantly different from each!\n__\nChallenge 7: Run either a t-test or a Wilcoxon rank sum test to test if there is a significant difference between Lake Rotoiti at Site 4 and Lake Rotorua at Site 5. You can choose whichever water quality variable you’d like to look at. Remember, you will need to start with the wq dataframe, select the relevant columns, filter LocationName and Parameter. Then you will pivot_wider (don’t forget to make a Date column and remove Unit), rename your columns, and run your statistical test plus a plot! HINT: Samples are not collected on the same date between Rotorua and Rotoiti, so you will need to format your dates as Month-Year (e.g., Jan-2021). You can do this using this line of code within your tidyverse pipe: mutate(Date = format(as.Date(Time), format = '%b-%Y'))\n\n\nClick to see a solution\n\n\nrotoiti_rotorua &lt;- wq %&gt;%\n    select(Time, LocationName, Value, Parameter, Unit) %&gt;%\n    filter(LocationName %in% c(\"Lake Rotorua at Site 5 (Integrated)\", \"Lake Rotoiti at Site 4 (Integrated)\"),\n        Parameter == \"TP (g/m^3)\")\n\nrotoiti_rotorua_wide &lt;- rotoiti_rotorua %&gt;%\n    mutate(Date = format(as.Date(Time), format = \"%b-%Y\")) %&gt;%\n    select(-Time, -Unit) %&gt;%\n    group_by(Date, LocationName, Parameter) %&gt;%\n    summarise(Value = mean(Value, na.rm = TRUE)) %&gt;%\n    pivot_wider(names_from = \"LocationName\", values_from = \"Value\") %&gt;%\n    ungroup()\n\nrotoiti_rotorua_wide &lt;- rotoiti_rotorua_wide %&gt;%\n    select(-Parameter) %&gt;%\n    rename(Rotoiti_TP = \"Lake Rotoiti at Site 4 (Integrated)\", Rotorua_TP = \"Lake Rotorua at Site 5 (Integrated)\")\n\n## if running a t-test\nt.test(log(rotoiti_rotorua_wide$Rotoiti_TP), log(rotoiti_rotorua_wide$Rotorua_TP))\n\n\n    Welch Two Sample t-test\n\ndata:  log(rotoiti_rotorua_wide$Rotoiti_TP) and log(rotoiti_rotorua_wide$Rotorua_TP)\nt = 3.0868, df = 231.54, p-value = 0.00227\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.05506289 0.24940133\nsample estimates:\nmean of x mean of y \n-3.829669 -3.981901 \n\nrotoiti_rotorua_wide %&gt;%\n    pivot_longer(Rotoiti_TP:Rotorua_TP, names_to = \"Site\", values_to = \"TP\") %&gt;%\n    ggplot(aes(x = Site, y = log(TP), fill = Site)) + geom_boxplot() + theme_bw() +\n    stat_compare_means(method = \"wilcox.test\", label = \"p.format\")\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_compare_means()`).\n\n\n\n\n\n\n\n\n## if running a wilcoxon test\nwilcox.test(rotoiti_rotorua_wide$Rotoiti_TP, rotoiti_rotorua_wide$Rotorua_TP)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  rotoiti_rotorua_wide$Rotoiti_TP and rotoiti_rotorua_wide$Rotorua_TP\nW = 8444.5, p-value = 0.003098\nalternative hypothesis: true location shift is not equal to 0\n\nrotoiti_rotorua_wide %&gt;%\n    pivot_longer(Rotoiti_TP:Rotorua_TP, names_to = \"Site\", values_to = \"TP\") %&gt;%\n    ggplot(aes(x = Site, y = TP, fill = Site)) + geom_boxplot() + theme_bw() + stat_compare_means(method = \"wilcox.test\",\n    label = \"p.format\")\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\nRemoved 3 rows containing non-finite outside the scale range\n(`stat_compare_means()`)."
  },
  {
    "objectID": "workshops/R_Tutorial_5_2025.html#anova",
    "href": "workshops/R_Tutorial_5_2025.html#anova",
    "title": "BOPRC R Tutorial 5 - Statistical Analyses in R",
    "section": "4.3 ANOVA",
    "text": "4.3 ANOVA\nWhat if we have more than two variables we want to test for differences across? This is where the ANOVA, or ANalysis Of VAriance comes in. An ANOVA assumes that your response variable is normally distributed and you are comparing differences across categorical predictors.\nIn this example, we will use an ANOVA to test for differences in secchi depth across season in Lake Okaro.\nWe will go back to our wq_okaro dataset. First, we need to filter to just secchi depth data and clean a few things up. Then, we test to see if secchi depth is normally distributed, and if not, we will transform it!\n\nhead(wq_okaro)\n\n                 Time Value  Parameter  Unit\n1 2015-01-22 10:27:00 0.900 TN (g/m^3) g/m^3\n2 2015-02-19 10:40:00 0.370 TN (g/m^3) g/m^3\n3 2015-03-19 09:50:00 0.400 TN (g/m^3) g/m^3\n4 2015-04-16 11:25:00 0.335 TN (g/m^3) g/m^3\n5 2015-05-21 09:50:00 0.583 TN (g/m^3) g/m^3\n6 2015-06-23 11:00:00 0.920 TN (g/m^3) g/m^3\n\nsecchi_okaro &lt;- wq_okaro %&gt;%\n    filter(Parameter == \"VC - SD (m)\") %&gt;%\n    select(-Unit, -Parameter) %&gt;%\n    rename(secchi_m = Value)\n\nhist(secchi_okaro$secchi_m)\n\n\n\n\n\n\n\nshapiro.test(secchi_okaro$secchi_m)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secchi_okaro$secchi_m\nW = 0.94404, p-value = 0.0003429\n\n\nLooks like Secchi is not normally distributed, so we will create a new log-transformed column and run the shapiro test again to check.\n\nsecchi_okaro &lt;- secchi_okaro %&gt;%\n    mutate(log_secchi_m = log(secchi_m))\n\nhist(secchi_okaro$log_secchi_m)\n\n\n\n\n\n\n\nshapiro.test(secchi_okaro$log_secchi_m)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secchi_okaro$log_secchi_m\nW = 0.97802, p-value = 0.09311\n\n\nP-value is greater than 0.05, so that looks better. We will run our ANOVA on log_secchi_m.\nNext, we need to create out seasons column, which is the variable by which we want to test if there are differences in Secchi depth. We first create a month column, and then create the season column, which is based on the month. I’ll do this first for ‘Summer’.\n\nsecchi_okaro &lt;- secchi_okaro %&gt;%\n    mutate(month = month(Time)) %&gt;%\n    mutate(season = case_when(month %in% c(12, 1, 2) ~ \"Summer\"))\n\n__\nChallenge 8: Now, finish creating the season column using case_when for “Autumn”, “Winter” and “Spring”. You will need to add TRUE ~ season as the last argument so that the values we set for Summer in the previous chunk of code remain (i.e., you’re not writing over your summer values you just did).\n\n\nClick to see a solution\n\n\nsecchi_okaro &lt;- secchi_okaro %&gt;%\n    mutate(season = case_when(month %in% c(3, 4, 5) ~ \"Autumn\", month %in% c(6, 7,\n        8) ~ \"Winter\", month %in% c(9, 10, 11) ~ \"Spring\", TRUE ~ season))\n\n\n\nNow that we have our season column, let’s make a boxplot of the data by season to see if there are any obvious patterns. We will order the season as a factor first to make sure it plots in an order that makes sense.\n\nsecchi_okaro$season &lt;- factor(secchi_okaro$season, levels = c(\"Spring\", \"Summer\",\n    \"Autumn\", \"Winter\"))\n\nggplot(secchi_okaro, aes(x = season, y = secchi_m)) + geom_boxplot() + theme_bw() +\n    ylab(\"Secchi depth (m)\")\n\n\n\n\n\n\n\n\nOk, there are some clear differences between the seasons here. I have a feeling this ANOVA is gonna be interesting…We will use the function aov to run the ANOVA on the log-transformed column and summary to look at the results.\n\nanova_secchi_okaro &lt;- aov(log_secchi_m ~ season, data = secchi_okaro)\nsummary(anova_secchi_okaro)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nseason       3  7.668  2.5561   11.31 2.02e-06 ***\nResiduals   96 21.689  0.2259                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe Pr(&gt;F) is very small, which tells us that there is a significant differences between seasons for Secchi depth.\nOne last thing we can check is which seasons are different from each other. We can run a Tukey test to see this.\n\ntukey_result &lt;- TukeyHSD(anova_secchi_okaro, conf.level = 0.95)\nprint(tukey_result)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = log_secchi_m ~ season, data = secchi_okaro)\n\n$season\n                    diff          lwr         upr     p adj\nSummer-Spring  0.4014153  0.063513659  0.73931693 0.0130941\nAutumn-Spring  0.7483003  0.410398707  1.08620198 0.0000005\nWinter-Spring  0.3485858 -0.002656331  0.69982791 0.0525363\nAutumn-Summer  0.3468850 -0.011875594  0.70564569 0.0619260\nWinter-Summer -0.0528295 -0.424182046  0.31852304 0.9823365\nWinter-Autumn -0.3997145 -0.771067094 -0.02836201 0.0297440\n\nggplot(secchi_okaro, aes(x = season, y = log(secchi_m))) + geom_boxplot() + theme_bw() +\n    ylab(\"Secchi depth (m)\")\n\n\n\n\n\n\n\n\nLooking at the p-adj column, we can see which seasons have statistically significant differences. Let’s use a p-value cutoff of p &lt; 0.05 is considered significant. Here, we can see that winter-spring, autumn-summer, and winter-summer are not statistically different from each other. If we look back at our boxplots, this looks like a reasonable result given the differences between distributions of those seasons.\nNice job! You’ve made it to the end of this statistical lesson. If you still have time, you can try running an ANOVA across seasons in another lake. Come to us with any questions!"
  },
  {
    "objectID": "workshops/R_Tutorial_3_2025.html",
    "href": "workshops/R_Tutorial_3_2025.html",
    "title": "Lesson 3 - Manipulating and plotting time series data in R",
    "section": "",
    "text": "This lesson is designed to provide you with experience in manipulating and plotting time series data.\nThe main packages that we will use in this tutorial are:\n\ntidyverse\nlubridate\nBoPRC2025\n\nBefore attempting to install these packages, make sure your Primary CRAN Repository is set to:\n\n“New Zealand [https] - University of Auckland”\n\nTo check this, click ‘Tools’ –&gt; ‘Global Options’ –&gt; ‘Packages’. Click ‘Change’ if you need to adjust this.\nYou can download most packages by clicking on the ‘Install’ button on the ‘packages’ tab in the lower right window pane. Then in the Install Packages popup, select ‘Repository (CRAN)’ from the ‘Install from’ drop box and type the name of the package you wish to download (e.g., dplyr).\nOnce all of these packages are installed you can load them using the ‘library’ function:\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(BoPRC2025) \n\nFirst we will load in our data. This data has been downloaded from Aquarius using the R script which you can find at scripts/download_data_aquarius.R if you’d like to see how the data were downloaded. For today, we are skipping that step and reading in directly from a .csv file which was written after the Aquarius download.\n\nwq &lt;- read.csv('./data/Lake_WQ_Timeseries.csv')\n\nNow, look at the wq dataframe by clicking on it in the environment and familiarise yourself with the columns. There is a lot of metadata here, but let’s select just a few which we want to work with, using the select function\n\nwq &lt;- wq %&gt;% \n  select(LocationName:Value, Parameter, Unit) # list the columns you want to keep, you can use, e.g. col1:col3 to select a range of columns\n\nOne of the columns that we have selected is the Time column, which includes both a date and a time. It is always best practice is to format date/time objects with the appropriate timezone, otherwise R will assume a timezone, and that can lead to the wrong date being set for your timestamp. Here, we will use a function called parse_date_time which looks at the Time column, and then provides a list (using c()) of potential formats that the column will be in. Here, we list two formats, the first one has YMD and HMS (hours, minutes, seconds), the second one just has YMD, as some of the values in the Time column don’t have an associated time next to the date. We pair this with the mutate function, which we will learn more about below.\nNOTE: there are many ways to format/parse dates and times in R. This is just one example!\n\nwq &lt;- wq %&gt;% mutate(Time = parse_date_time(Time,c(\"%Y-%m-%d %H:%M:%S\",\"%Y-%m-%d\"), tz = \"etc/GMT+12\"))\n\n\nChallenge 1: What is the structure of wq now that you have updated the Time column?\n\n\nClick to see a solution\n\n\nstr(wq)\n\n'data.frame':   6469 obs. of  5 variables:\n $ LocationName: chr  \"Lake Rotoma at Site 1 (Integrated)\" \"Lake Rotoma at Site 1 (Integrated)\" \"Lake Rotoma at Site 1 (Integrated)\" \"Lake Rotoma at Site 1 (Integrated)\" ...\n $ Time        : POSIXct, format: \"2015-01-20 07:53:00\" \"2015-02-17 07:40:00\" ...\n $ Value       : num  0.117 0.115 0.111 0.123 0.124 ...\n $ Parameter   : chr  \"TN (g/m^3)\" \"TN (g/m^3)\" \"TN (g/m^3)\" \"TN (g/m^3)\" ...\n $ Unit        : chr  \"g/m^3\" \"g/m^3\" \"g/m^3\" \"g/m^3\" ...\n\n# This shows that the Time column is now a POSIXct object\n\n\n\nUsing the unique function, let’s see what lakes which are included in this dataset.\n\nunique(wq$LocationName)\n\n [1] \"Lake Rotoma at Site 1 (Integrated)\"       \n [2] \"Lake Rotoehu at Site 3 (Integrated)\"      \n [3] \"Lake Rotoiti at Site 4 (Integrated)\"      \n [4] \"Lake Rotoiti at Site 3 (Integrated)\"      \n [5] \"Lake Rotoiti at Okawa Bay (Integrated)\"   \n [6] \"Lake Rotorua at Site 2 (Integrated)\"      \n [7] \"Lake Okataina at Site 1 (Integrated)\"     \n [8] \"Lake Okareka at Site 1 (Integrated)\"      \n [9] \"Lake Tikitapu at Site 1 (Integrated)\"     \n[10] \"Lake Rerewhakaaitu at Site 1 (Integrated)\"\n[11] \"Lake Okaro at Site 1 (Integrated)\"        \n[12] \"Lake Rotorua at Site 5 (Integrated)\"      \n[13] \"Lake Tarawera at Site 5 (Integrated)\"     \n[14] \"Lake Rotomahana at Site 2 (Integrated)\"   \n\n\n\nChallenge 2: Using the same unique function, what water quality variables are included in this dataset, in the Parameter column?\n\n\nClick to see a solution\n\n\nunique(wq$Parameter)\n\n[1] \"TN (g/m^3)\"    \"TP (g/m^3)\"    \"CHLA (mg/m^3)\" \"VC - SD (m)\"  \n\n# This shows we have total nitrogen, total phosphorus, chlorophyll-a, and\n# Secchi depth\n\n\n\nThe names of the parameters have spaces and symbols in them which can be annoying to work with in R. Let’s clean that up. We will use a function called recode which can be used to change the name of a value in a column. Here, we are saying take the wq dataframe, and mutate the column Parameter such that the values of Parameter which currently equal “TN (g/m^3)”, will be rewritten as “TN_gm3”. We will also do this for TP here.\n\nwq &lt;- wq %&gt;%\n    mutate(Parameter = recode(Parameter, `TN (g/m^3)` = \"TN_gm3\"), Parameter = recode(Parameter,\n        `TP (g/m^3)` = \"TP_gm3\"))\n\nAs with anything in R, there are multiple ways to rename entries within a column like we have just done. We will rename the TN and TP values in the Parameter column using the case_when function so you can learn another method. Sometimes one method may be more intuitive to you than another.\n\nwq &lt;- wq %&gt;% \n  mutate(Parameter = case_when(  # create a new `Parameter` column based on a set of conditions\n    Parameter == \"TN (g/m^3)\" ~ \"TN_gm3\", # first condition: if the value of Parameter is \"TN (g/m^3)\", change it to \"TN_gm3\"\n    Parameter == \"TP (g/m^3)\" ~ \"TP_gm3\", # same but for TP\n    TRUE ~ Parameter)) # for any other cases, keep the original values of Parameter\n\n# provide case_when example\n\n\nChallenge 3: We have done this for TN and TP. Now try using the same method to rename chlorophyll-a and Secchi depth using either recode or case_when. Make sure to name the new columns chla_mgm3 and secchi_m (we will use these same names later in the code so they will need to match!)\n\n\nClick to see a solution\n\n\nwq &lt;- wq %&gt;%\n    mutate(Parameter = recode(Parameter, `CHLA (mg/m^3)` = \"chla_mgm3\"), Parameter = recode(Parameter,\n        `VC - SD (m)` = \"secchi_m\"))\n\n\n\nNow let’s make a plot of our data, using the facet_wrap function to display the different parameters\n\nggplot(wq, aes(x = as.Date(Time), y = Value, color = LocationName)) + geom_point() +\n    facet_wrap(~Parameter, scales = \"free\") + theme_bw()\n\n\n\n\n\n\n\n# the scales = 'free' in the facet_wrap() function allows the x and y-axes to\n# vary by each panel\n\n\n\nLet’s say we’re interested in a plot of chl-a, but we want to color it based on the Secchi depth in that lake. Our dataset is in long format, so in order to do this, we need to make it into wide format (e.g., instead of Parameters as a column, TN, TP, chla, and Secchi will be their own columns, with the values in that column). We will use the pivot_wider function to do this, where you give the function the name of the column where the new columns will come from (here names_from = 'Parameter'), and the name of the column where the actual numbers will come from (here values_from = 'Value')\n\nwq_wide &lt;- wq %&gt;%\n    pivot_wider(names_from = \"Parameter\", values_from = \"Value\")\n\nWarning: Values from `Value` are not uniquely identified; output will contain list-cols.\n• Use `values_fn = list` to suppress this warning.\n• Use `values_fn = {summary_fun}` to summarise duplicates.\n• Use the following dplyr code to identify duplicates.\n  {data} |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(LocationName, Time, Unit,\n  Parameter)) |&gt;\n  dplyr::filter(n &gt; 1L)\n\n\nThat threw some warnings, so let’s look at the dataframe and see if everything looks ok. When we open up wq_wide, we see there are a lot of “NULL” values for the different columns–that doesn’t look right. That is because our Time column is very specific, and includes not just dates but times which are not common across all the parameters. The time components isn’t really important in this case. We also have the Unit column, which is not the same across parameters and is causing an issue. Let’s create a Date column, remove Time and Unit, and try making the dataframe wide again\n\nwq_wide &lt;- wq %&gt;%\n    mutate(Date = as.Date(Time)) %&gt;%\n    select(-Time, -Unit) %&gt;%\n    pivot_wider(names_from = \"Parameter\", values_from = \"Value\")\n\nWarning: Values from `Value` are not uniquely identified; output will contain list-cols.\n• Use `values_fn = list` to suppress this warning.\n• Use `values_fn = {summary_fun}` to summarise duplicates.\n• Use the following dplyr code to identify duplicates.\n  {data} |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(LocationName, Date, Parameter)) |&gt;\n  dplyr::filter(n &gt; 1L)\n\n\nHmm, that still throws a warning. If we look at wq_wide again, we see that there are some columns which have two values in them (e.g., Lake Rotoma on 2015-01-20 has two entries for TP). To fix this, let’s take the average on a given day for a given lake if there is more than one reading. We will need to introduce a couple of new functions to accomplish this.\n\n\n\ngroup_by is a tidyverse function which allows you to do calculations by different groups (e.g., the LocationName column). It is usually paired with another function which does the calculation. For example, summarise is another tidyverse function which, as it sounds, summarises by a given function. I often use this to take the mean, minimum, or some other summary statistic. This function results in a shorter dataframe, because you’ve summarised the values by your grouping factors. We will pair group_by with summarise to create summary statistics for each lake.\n\nwq_wide &lt;- wq %&gt;% \n  mutate(Date = as.Date(Time)) %&gt;% # keeping these lines in our workflow to remove Time and Unit\n  select(-Time, -Unit) %&gt;% \n  group_by(LocationName, Date, Parameter) %&gt;% \n  summarise(Value = mean(Value, na.rm = TRUE)) %&gt;% \n  pivot_wider(names_from = 'Parameter', values_from = 'Value') # then we pivot wider\n\nViola! No warnings and our dataframe looks good (make sure you look at it)!! Ok, now let’s make a plot of chl-a over time, but colored in by Secchi (our original goal before all that data manipulation…)\n\nwq_wide %&gt;% \n  filter(!is.na(secchi_m)) %&gt;% # some values have NA for secchi so we will remove those\n  ggplot(aes(x = as.Date(Date), y = chla_mgm3, color = secchi_m)) +\n  geom_point() +\n  facet_wrap(~LocationName) +\n  scale_color_distiller(palette = 'YlGnBu', direction = 2) +\n  theme_bw() +\n  scale_y_log10() # this log-transforms the y axis and makes it easier to see the variability across sites\n\nWarning: Removed 34 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n# scale_color_distiller changes the color scheme,  you can google scale_color_distiller to find out other palettes you can use, direction = 2 just changes whether the scales goes from blue to yellow with blue as high or low, in this case, we want blue to be high. try changing direction = 1 and see what happens\n\n\nChallenge 4a: Now that we’ve used pivot_wider, try to use pivot_longer to turn your dataframe back into longer format\n\n\nClick to see a solution\n\n\nwq_long &lt;- wq_wide %&gt;%\n    pivot_longer(TN_gm3:secchi_m, names_to = \"Parameter\", values_to = \"Value\")\n\n# first you specify which columns are getting pivot-ted longer, we can use the\n# colon : to say all the columns between TN and secchi\n\n# being able to pivot between wide and long format is really helpful for\n# different types of analyses and plotting!\n\n\n\n\nChallenge 4b: Now that you’ve made your wq_long dataframe, try making a plot with Date on the x-axis, Value on the y-axis, color by LocationName, and facet_wrap by Parameter. Use geom_line instead of geom_point\n\n\nClick to see a solution\n\n\nggplot(wq_long, aes(x = as.Date(Date), y = Value, color = LocationName)) + geom_line() +\n    facet_wrap(~Parameter, scales = \"free\") + theme_bw() + scale_y_log10()\n\nWarning: Removed 19 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ve now plotted the full time series but we want to get a more summarised overview of the water quality across the lakes, so we will calculate some summary statistics. Let’s calculate the annual means for each variable and lake. First we need to create a new column which represents the year. We will use the function year in the lubridate package\n\nwq_summary &lt;- wq %&gt;%\n    mutate(year = year(Time)) %&gt;%\n    group_by(LocationName, Parameter, year) %&gt;%\n    summarise(mean = mean(Value, na.rm = TRUE), median = median(Value, na.rm = TRUE),\n        min = min(Value, na.rm = TRUE), max = max(Value, na.rm = TRUE), sd = sd(Value,\n            na.rm = TRUE))\n\nOften, we actually need to calculate annual averages by the hydroyear, instead of the year. To do this, let’s use the Bathing_Season function in the BoPRC2025 package, which calculates the hydroyear.\n\nwq_summary &lt;- wq %&gt;%\n    # mutate(year = year(Time)) %&gt;%\nmutate(hydroyear = Bathing_Season(Time)) %&gt;%\n    group_by(LocationName, Parameter, hydroyear) %&gt;%\n    summarise(mean = mean(Value, na.rm = TRUE), median = median(Value, na.rm = TRUE),\n        min = min(Value, na.rm = TRUE), max = max(Value, na.rm = TRUE), sd = sd(Value,\n            na.rm = TRUE))\n\nView the wq_summary dataframe and familiarise yourself with it. Let’s plot the chl-a data to visualize it a bit more clearly.\n\nwq_summary %&gt;% \n  filter(Parameter=='chla_mgm3') %&gt;% # only plot TN\n  ggplot(aes(x = hydroyear, y = mean)) +\n  geom_point() +\n  facet_wrap(~LocationName, scales = 'free') +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 75, hjust = 1))  +\n  ylab('Mean Chl-a (mgm/m3)')\n\n\n\n\n\n\n\n\n\nChallenge 5: That’s a lot of lakes to wrap your head around. For this challenge, create a plot for just Lake Rotorua at Site 2, and facet by Parameter\n\n\nClick to see a solution\n\n\nwq_summary %&gt;% \n  filter(LocationName==\"Lake Rotorua at Site 2 (Integrated)\") %&gt;% # only plot TN\n  ggplot(aes(x = hydroyear, y = mean)) +\n  geom_point(size = 2) +\n  facet_wrap(~Parameter, scales = 'free') +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 75, hjust = 1)) # this rotates the x-axis label since the LocationNames are long\n\n\n\n\n\n\n\n\n\n\nWe can also add the standard deviation as error bars using geom_errorbar.\n\nwq_summary %&gt;% \n  filter(LocationName==\"Lake Rotorua at Site 2 (Integrated)\") %&gt;% # only plot TN\n  ggplot(aes(x = hydroyear, y = mean)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd, width = 0.2)) +\n  facet_wrap(~Parameter, scales = 'free') +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 75, hjust = 1)) # this rotates the x-axis label since the LocationNames are long\n\n\n\n\n\n\n\n\nHowever, we know there is strong seasonal variability. Let’s look at seasonal means instead of overall\n\n\n\nThe mutate function creates an entirely new column in our dataframe. This works similarly to summarise which we used above, except instead of summarising into a smaller dataframe, we use mutate across all our data and maintain the same number of rows. In order to do seasonal means, we need to first create a season identifier. We will pair mutate with case_when which you used earlier. This function chains together multiple ifelse statements. Essentially, it allows you to perform a multiple conditional operations which says if(this condition), then do X, if not, do Y. Here, we are saying if the month of our time column is 12, 1, 2, make the new column ‘season’ = ‘summer’, and so on for the other month combination. The last argument TRUE ~ NA_character_ says, if none of the conditions are met, assign it as NA.\n\n# go back to our original wq dataframe, not the summarised one and add a new\n# column: season\nwq &lt;- wq %&gt;%\n    mutate(season = case_when(month(Time) %in% c(12, 1, 2) ~ \"summer\", month(Time) %in%\n        c(3, 4, 5) ~ \"autumn\", month(Time) %in% c(6, 7, 8) ~ \"winter\", month(Time) %in%\n        c(9, 10, 11) ~ \"spring\", TRUE ~ NA_character_))  # default case, if needed\n\nLet’s plot the range of values across each season\n\nggplot(wq, aes(x = season, y = Value)) + geom_boxplot() + facet_wrap(~Parameter,\n    scales = \"free\") + theme_bw() + scale_y_log10()\n\n\n\n\n\n\n\n\nChallenge 6: It’s nice to see the boxplots, but we want the actual numbers for median, min, max, etc.. Calculate summary statistics for each lake, season, and parameter. HINT: We will bring back our friends group_by and summarise for this.\n\n\nClick to see a solution\n\n\nwq_season_summary &lt;- wq %&gt;%\n    group_by(LocationName, season, Parameter) %&gt;%\n    summarise(mean = mean(Value, na.rm = TRUE), median = median(Value, na.rm = TRUE),\n        min = min(Value, na.rm = TRUE), max = max(Value, na.rm = TRUE), sd = sd(Value,\n            na.rm = TRUE), perc_95 = quantile(Value, 0.95))\n\n# Open up your dataframe and see if all looks good. There should be one value\n# for each season, lake, and parameter\n\n\n\n\n\n\nWe have a dataframe with the ranges of the NPSFM bands for each variable. We will need to read this in, merge together with our wq_summary dataframe, which has the annual median values for each variable. Then we will plot the data. But first we will have to do a little data manipulating…\n\n# read in bands\nbands &lt;- read.csv(\"./data/NPSFM_bands.csv\")\n# we want to join `bands` with the `wq` dataframe, but the column name for\n# `Parameter` is called `variable`. We will rename this so it matches with `wq`\n\nbands &lt;- bands %&gt;%\n    rename(Parameter = variable)\n\nThe values of TN and TP in bands$Parameter are in mg/m3, whereas in wq_summary they are in g/m3. We need to first convert TN and TP in wq_summary into mg/m3 before we can merge the two dataframes together.\n\nwq_summary &lt;- wq_summary %&gt;% \n  select(LocationName, Parameter, hydroyear, median) %&gt;% # select the columns we need\n  mutate(median = ifelse(Parameter %in% c('TN_gm3', 'TP_gm3'), median*1000, median),\n         Parameter = recode(Parameter, \n                            'TN_gm3' = 'TN_mgm3',\n                            'TP_gm3' = 'TP_mgm3'))\nprint(unique(wq_summary$Parameter))\n\n[1] \"TN_mgm3\"   \"TP_mgm3\"   \"chla_mgm3\" \"secchi_m\" \n\n\nNow that we have the columns in both of the dataframes wq_summary and bands set up properly, we can combine the two dataframes using the function left_join. This is another tidyverse function that merges two dataframes based on one or more common columns. It will keep all the rows from the first (left) dataframe and add any matching information in the second (right) dataframe. Here the matching columns is Parameter\n\nnof &lt;- left_join(wq_summary, bands, by = \"Parameter\")\n\nWarning in left_join(wq_summary, bands, by = \"Parameter\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 5 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nThis gives us a warning that there are “many-to-many relationships between x and y.” Sometimes this warning means that there is something wrong with your dataframe merge, but in this case, this is actually ok. It is telling us that in bands there are multiple matches for a single value of Parameter in wq_summary. That is because there are four values of bands$band (a, b, c, and d) which correspond to a single row in wq_summary. This has resulted in our new dataframe nof being much longer than the original wq_summary but that is expected behavior so we can ignore this warning.\nNow that we have our matching dataframe, we need to create maximum and minimum x values for which the color shading will be mapped onto our plot. These simply need to correspond to maximum and minimum years of our dataframe\n\nnof &lt;- nof %&gt;%\n    group_by(Parameter) %&gt;%\n    mutate(x_max = max(hydroyear), x_min = min(hydroyear))\n\nIf we look at nof again, we should have a minimum and maximum column for both x and y. We will use these in our plotting by adding a layer using geom_rect to map the colors of the different bands behind our points\n\nggplot(nof, aes(x = hydroyear, y = median, color = as.factor(LocationName))) + geom_rect(aes(xmin = x_min,\n    xmax = x_max, ymin = y_min, ymax = y_max, fill = band, alpha = 0.2), color = NA) +\n    geom_point(size = 2) + scale_fill_manual(values = c(\"#00A2E1FF\", \"#62BD19FF\",\n    \"#FFC726FF\", \"#FF671FFF\")) + facet_wrap(~Parameter, scales = \"free\") + labs(color = \"Site\") +\n    theme_bw() + theme(axis.text.x = element_text(angle = 75, hjust = 1)) + scale_y_log10()\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 153 rows containing missing values or values outside the scale range\n(`geom_rect()`).\n\n\n\n\n\n\n\n\n\nChallenge 7: Secchi depth is not currently assessed as part of the NPSFM. Let’s remove it from our plot using the filter function:\n\n\nClick to see a solution\n\n\nnof %&gt;%\n    filter(Parameter != \"secchi_m\") %&gt;%\n    ggplot(aes(x = hydroyear, y = median, color = as.factor(LocationName))) + geom_rect(aes(xmin = x_min,\n    xmax = x_max, ymin = y_min, ymax = y_max, fill = band), color = NA) + geom_point(size = 2) +\n    scale_fill_manual(values = c(\"#00A2E1FF\", \"#62BD19FF\", \"#FFC726FF\", \"#FF671FFF\")) +\n    facet_wrap(~Parameter, scales = \"free\", nrow = 2) + labs(color = \"Site\") + theme_bw() +\n    theme(axis.text.x = element_text(angle = 75, hjust = 1)) + scale_y_log10()\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values."
  },
  {
    "objectID": "workshops/R_Tutorial_3_2025.html#overview",
    "href": "workshops/R_Tutorial_3_2025.html#overview",
    "title": "Lesson 3 - Manipulating and plotting time series data in R",
    "section": "",
    "text": "This lesson is designed to provide you with experience in manipulating and plotting time series data.\nThe main packages that we will use in this tutorial are:\n\ntidyverse\nlubridate\nBoPRC2025\n\nBefore attempting to install these packages, make sure your Primary CRAN Repository is set to:\n\n“New Zealand [https] - University of Auckland”\n\nTo check this, click ‘Tools’ –&gt; ‘Global Options’ –&gt; ‘Packages’. Click ‘Change’ if you need to adjust this.\nYou can download most packages by clicking on the ‘Install’ button on the ‘packages’ tab in the lower right window pane. Then in the Install Packages popup, select ‘Repository (CRAN)’ from the ‘Install from’ drop box and type the name of the package you wish to download (e.g., dplyr).\nOnce all of these packages are installed you can load them using the ‘library’ function:\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(BoPRC2025) \n\nFirst we will load in our data. This data has been downloaded from Aquarius using the R script which you can find at scripts/download_data_aquarius.R if you’d like to see how the data were downloaded. For today, we are skipping that step and reading in directly from a .csv file which was written after the Aquarius download.\n\nwq &lt;- read.csv('./data/Lake_WQ_Timeseries.csv')\n\nNow, look at the wq dataframe by clicking on it in the environment and familiarise yourself with the columns. There is a lot of metadata here, but let’s select just a few which we want to work with, using the select function\n\nwq &lt;- wq %&gt;% \n  select(LocationName:Value, Parameter, Unit) # list the columns you want to keep, you can use, e.g. col1:col3 to select a range of columns\n\nOne of the columns that we have selected is the Time column, which includes both a date and a time. It is always best practice is to format date/time objects with the appropriate timezone, otherwise R will assume a timezone, and that can lead to the wrong date being set for your timestamp. Here, we will use a function called parse_date_time which looks at the Time column, and then provides a list (using c()) of potential formats that the column will be in. Here, we list two formats, the first one has YMD and HMS (hours, minutes, seconds), the second one just has YMD, as some of the values in the Time column don’t have an associated time next to the date. We pair this with the mutate function, which we will learn more about below.\nNOTE: there are many ways to format/parse dates and times in R. This is just one example!\n\nwq &lt;- wq %&gt;% mutate(Time = parse_date_time(Time,c(\"%Y-%m-%d %H:%M:%S\",\"%Y-%m-%d\"), tz = \"etc/GMT+12\"))\n\n\nChallenge 1: What is the structure of wq now that you have updated the Time column?\n\n\nClick to see a solution\n\n\nstr(wq)\n\n'data.frame':   6469 obs. of  5 variables:\n $ LocationName: chr  \"Lake Rotoma at Site 1 (Integrated)\" \"Lake Rotoma at Site 1 (Integrated)\" \"Lake Rotoma at Site 1 (Integrated)\" \"Lake Rotoma at Site 1 (Integrated)\" ...\n $ Time        : POSIXct, format: \"2015-01-20 07:53:00\" \"2015-02-17 07:40:00\" ...\n $ Value       : num  0.117 0.115 0.111 0.123 0.124 ...\n $ Parameter   : chr  \"TN (g/m^3)\" \"TN (g/m^3)\" \"TN (g/m^3)\" \"TN (g/m^3)\" ...\n $ Unit        : chr  \"g/m^3\" \"g/m^3\" \"g/m^3\" \"g/m^3\" ...\n\n# This shows that the Time column is now a POSIXct object\n\n\n\nUsing the unique function, let’s see what lakes which are included in this dataset.\n\nunique(wq$LocationName)\n\n [1] \"Lake Rotoma at Site 1 (Integrated)\"       \n [2] \"Lake Rotoehu at Site 3 (Integrated)\"      \n [3] \"Lake Rotoiti at Site 4 (Integrated)\"      \n [4] \"Lake Rotoiti at Site 3 (Integrated)\"      \n [5] \"Lake Rotoiti at Okawa Bay (Integrated)\"   \n [6] \"Lake Rotorua at Site 2 (Integrated)\"      \n [7] \"Lake Okataina at Site 1 (Integrated)\"     \n [8] \"Lake Okareka at Site 1 (Integrated)\"      \n [9] \"Lake Tikitapu at Site 1 (Integrated)\"     \n[10] \"Lake Rerewhakaaitu at Site 1 (Integrated)\"\n[11] \"Lake Okaro at Site 1 (Integrated)\"        \n[12] \"Lake Rotorua at Site 5 (Integrated)\"      \n[13] \"Lake Tarawera at Site 5 (Integrated)\"     \n[14] \"Lake Rotomahana at Site 2 (Integrated)\"   \n\n\n\nChallenge 2: Using the same unique function, what water quality variables are included in this dataset, in the Parameter column?\n\n\nClick to see a solution\n\n\nunique(wq$Parameter)\n\n[1] \"TN (g/m^3)\"    \"TP (g/m^3)\"    \"CHLA (mg/m^3)\" \"VC - SD (m)\"  \n\n# This shows we have total nitrogen, total phosphorus, chlorophyll-a, and\n# Secchi depth\n\n\n\nThe names of the parameters have spaces and symbols in them which can be annoying to work with in R. Let’s clean that up. We will use a function called recode which can be used to change the name of a value in a column. Here, we are saying take the wq dataframe, and mutate the column Parameter such that the values of Parameter which currently equal “TN (g/m^3)”, will be rewritten as “TN_gm3”. We will also do this for TP here.\n\nwq &lt;- wq %&gt;%\n    mutate(Parameter = recode(Parameter, `TN (g/m^3)` = \"TN_gm3\"), Parameter = recode(Parameter,\n        `TP (g/m^3)` = \"TP_gm3\"))\n\nAs with anything in R, there are multiple ways to rename entries within a column like we have just done. We will rename the TN and TP values in the Parameter column using the case_when function so you can learn another method. Sometimes one method may be more intuitive to you than another.\n\nwq &lt;- wq %&gt;% \n  mutate(Parameter = case_when(  # create a new `Parameter` column based on a set of conditions\n    Parameter == \"TN (g/m^3)\" ~ \"TN_gm3\", # first condition: if the value of Parameter is \"TN (g/m^3)\", change it to \"TN_gm3\"\n    Parameter == \"TP (g/m^3)\" ~ \"TP_gm3\", # same but for TP\n    TRUE ~ Parameter)) # for any other cases, keep the original values of Parameter\n\n# provide case_when example\n\n\nChallenge 3: We have done this for TN and TP. Now try using the same method to rename chlorophyll-a and Secchi depth using either recode or case_when. Make sure to name the new columns chla_mgm3 and secchi_m (we will use these same names later in the code so they will need to match!)\n\n\nClick to see a solution\n\n\nwq &lt;- wq %&gt;%\n    mutate(Parameter = recode(Parameter, `CHLA (mg/m^3)` = \"chla_mgm3\"), Parameter = recode(Parameter,\n        `VC - SD (m)` = \"secchi_m\"))\n\n\n\nNow let’s make a plot of our data, using the facet_wrap function to display the different parameters\n\nggplot(wq, aes(x = as.Date(Time), y = Value, color = LocationName)) + geom_point() +\n    facet_wrap(~Parameter, scales = \"free\") + theme_bw()\n\n\n\n\n\n\n\n# the scales = 'free' in the facet_wrap() function allows the x and y-axes to\n# vary by each panel\n\n\n\nLet’s say we’re interested in a plot of chl-a, but we want to color it based on the Secchi depth in that lake. Our dataset is in long format, so in order to do this, we need to make it into wide format (e.g., instead of Parameters as a column, TN, TP, chla, and Secchi will be their own columns, with the values in that column). We will use the pivot_wider function to do this, where you give the function the name of the column where the new columns will come from (here names_from = 'Parameter'), and the name of the column where the actual numbers will come from (here values_from = 'Value')\n\nwq_wide &lt;- wq %&gt;%\n    pivot_wider(names_from = \"Parameter\", values_from = \"Value\")\n\nWarning: Values from `Value` are not uniquely identified; output will contain list-cols.\n• Use `values_fn = list` to suppress this warning.\n• Use `values_fn = {summary_fun}` to summarise duplicates.\n• Use the following dplyr code to identify duplicates.\n  {data} |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(LocationName, Time, Unit,\n  Parameter)) |&gt;\n  dplyr::filter(n &gt; 1L)\n\n\nThat threw some warnings, so let’s look at the dataframe and see if everything looks ok. When we open up wq_wide, we see there are a lot of “NULL” values for the different columns–that doesn’t look right. That is because our Time column is very specific, and includes not just dates but times which are not common across all the parameters. The time components isn’t really important in this case. We also have the Unit column, which is not the same across parameters and is causing an issue. Let’s create a Date column, remove Time and Unit, and try making the dataframe wide again\n\nwq_wide &lt;- wq %&gt;%\n    mutate(Date = as.Date(Time)) %&gt;%\n    select(-Time, -Unit) %&gt;%\n    pivot_wider(names_from = \"Parameter\", values_from = \"Value\")\n\nWarning: Values from `Value` are not uniquely identified; output will contain list-cols.\n• Use `values_fn = list` to suppress this warning.\n• Use `values_fn = {summary_fun}` to summarise duplicates.\n• Use the following dplyr code to identify duplicates.\n  {data} |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(LocationName, Date, Parameter)) |&gt;\n  dplyr::filter(n &gt; 1L)\n\n\nHmm, that still throws a warning. If we look at wq_wide again, we see that there are some columns which have two values in them (e.g., Lake Rotoma on 2015-01-20 has two entries for TP). To fix this, let’s take the average on a given day for a given lake if there is more than one reading. We will need to introduce a couple of new functions to accomplish this.\n\n\n\ngroup_by is a tidyverse function which allows you to do calculations by different groups (e.g., the LocationName column). It is usually paired with another function which does the calculation. For example, summarise is another tidyverse function which, as it sounds, summarises by a given function. I often use this to take the mean, minimum, or some other summary statistic. This function results in a shorter dataframe, because you’ve summarised the values by your grouping factors. We will pair group_by with summarise to create summary statistics for each lake.\n\nwq_wide &lt;- wq %&gt;% \n  mutate(Date = as.Date(Time)) %&gt;% # keeping these lines in our workflow to remove Time and Unit\n  select(-Time, -Unit) %&gt;% \n  group_by(LocationName, Date, Parameter) %&gt;% \n  summarise(Value = mean(Value, na.rm = TRUE)) %&gt;% \n  pivot_wider(names_from = 'Parameter', values_from = 'Value') # then we pivot wider\n\nViola! No warnings and our dataframe looks good (make sure you look at it)!! Ok, now let’s make a plot of chl-a over time, but colored in by Secchi (our original goal before all that data manipulation…)\n\nwq_wide %&gt;% \n  filter(!is.na(secchi_m)) %&gt;% # some values have NA for secchi so we will remove those\n  ggplot(aes(x = as.Date(Date), y = chla_mgm3, color = secchi_m)) +\n  geom_point() +\n  facet_wrap(~LocationName) +\n  scale_color_distiller(palette = 'YlGnBu', direction = 2) +\n  theme_bw() +\n  scale_y_log10() # this log-transforms the y axis and makes it easier to see the variability across sites\n\nWarning: Removed 34 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n# scale_color_distiller changes the color scheme,  you can google scale_color_distiller to find out other palettes you can use, direction = 2 just changes whether the scales goes from blue to yellow with blue as high or low, in this case, we want blue to be high. try changing direction = 1 and see what happens\n\n\nChallenge 4a: Now that we’ve used pivot_wider, try to use pivot_longer to turn your dataframe back into longer format\n\n\nClick to see a solution\n\n\nwq_long &lt;- wq_wide %&gt;%\n    pivot_longer(TN_gm3:secchi_m, names_to = \"Parameter\", values_to = \"Value\")\n\n# first you specify which columns are getting pivot-ted longer, we can use the\n# colon : to say all the columns between TN and secchi\n\n# being able to pivot between wide and long format is really helpful for\n# different types of analyses and plotting!\n\n\n\n\nChallenge 4b: Now that you’ve made your wq_long dataframe, try making a plot with Date on the x-axis, Value on the y-axis, color by LocationName, and facet_wrap by Parameter. Use geom_line instead of geom_point\n\n\nClick to see a solution\n\n\nggplot(wq_long, aes(x = as.Date(Date), y = Value, color = LocationName)) + geom_line() +\n    facet_wrap(~Parameter, scales = \"free\") + theme_bw() + scale_y_log10()\n\nWarning: Removed 19 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ve now plotted the full time series but we want to get a more summarised overview of the water quality across the lakes, so we will calculate some summary statistics. Let’s calculate the annual means for each variable and lake. First we need to create a new column which represents the year. We will use the function year in the lubridate package\n\nwq_summary &lt;- wq %&gt;%\n    mutate(year = year(Time)) %&gt;%\n    group_by(LocationName, Parameter, year) %&gt;%\n    summarise(mean = mean(Value, na.rm = TRUE), median = median(Value, na.rm = TRUE),\n        min = min(Value, na.rm = TRUE), max = max(Value, na.rm = TRUE), sd = sd(Value,\n            na.rm = TRUE))\n\nOften, we actually need to calculate annual averages by the hydroyear, instead of the year. To do this, let’s use the Bathing_Season function in the BoPRC2025 package, which calculates the hydroyear.\n\nwq_summary &lt;- wq %&gt;%\n    # mutate(year = year(Time)) %&gt;%\nmutate(hydroyear = Bathing_Season(Time)) %&gt;%\n    group_by(LocationName, Parameter, hydroyear) %&gt;%\n    summarise(mean = mean(Value, na.rm = TRUE), median = median(Value, na.rm = TRUE),\n        min = min(Value, na.rm = TRUE), max = max(Value, na.rm = TRUE), sd = sd(Value,\n            na.rm = TRUE))\n\nView the wq_summary dataframe and familiarise yourself with it. Let’s plot the chl-a data to visualize it a bit more clearly.\n\nwq_summary %&gt;% \n  filter(Parameter=='chla_mgm3') %&gt;% # only plot TN\n  ggplot(aes(x = hydroyear, y = mean)) +\n  geom_point() +\n  facet_wrap(~LocationName, scales = 'free') +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 75, hjust = 1))  +\n  ylab('Mean Chl-a (mgm/m3)')\n\n\n\n\n\n\n\n\n\nChallenge 5: That’s a lot of lakes to wrap your head around. For this challenge, create a plot for just Lake Rotorua at Site 2, and facet by Parameter\n\n\nClick to see a solution\n\n\nwq_summary %&gt;% \n  filter(LocationName==\"Lake Rotorua at Site 2 (Integrated)\") %&gt;% # only plot TN\n  ggplot(aes(x = hydroyear, y = mean)) +\n  geom_point(size = 2) +\n  facet_wrap(~Parameter, scales = 'free') +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 75, hjust = 1)) # this rotates the x-axis label since the LocationNames are long\n\n\n\n\n\n\n\n\n\n\nWe can also add the standard deviation as error bars using geom_errorbar.\n\nwq_summary %&gt;% \n  filter(LocationName==\"Lake Rotorua at Site 2 (Integrated)\") %&gt;% # only plot TN\n  ggplot(aes(x = hydroyear, y = mean)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd, width = 0.2)) +\n  facet_wrap(~Parameter, scales = 'free') +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 75, hjust = 1)) # this rotates the x-axis label since the LocationNames are long\n\n\n\n\n\n\n\n\nHowever, we know there is strong seasonal variability. Let’s look at seasonal means instead of overall\n\n\n\nThe mutate function creates an entirely new column in our dataframe. This works similarly to summarise which we used above, except instead of summarising into a smaller dataframe, we use mutate across all our data and maintain the same number of rows. In order to do seasonal means, we need to first create a season identifier. We will pair mutate with case_when which you used earlier. This function chains together multiple ifelse statements. Essentially, it allows you to perform a multiple conditional operations which says if(this condition), then do X, if not, do Y. Here, we are saying if the month of our time column is 12, 1, 2, make the new column ‘season’ = ‘summer’, and so on for the other month combination. The last argument TRUE ~ NA_character_ says, if none of the conditions are met, assign it as NA.\n\n# go back to our original wq dataframe, not the summarised one and add a new\n# column: season\nwq &lt;- wq %&gt;%\n    mutate(season = case_when(month(Time) %in% c(12, 1, 2) ~ \"summer\", month(Time) %in%\n        c(3, 4, 5) ~ \"autumn\", month(Time) %in% c(6, 7, 8) ~ \"winter\", month(Time) %in%\n        c(9, 10, 11) ~ \"spring\", TRUE ~ NA_character_))  # default case, if needed\n\nLet’s plot the range of values across each season\n\nggplot(wq, aes(x = season, y = Value)) + geom_boxplot() + facet_wrap(~Parameter,\n    scales = \"free\") + theme_bw() + scale_y_log10()\n\n\n\n\n\n\n\n\nChallenge 6: It’s nice to see the boxplots, but we want the actual numbers for median, min, max, etc.. Calculate summary statistics for each lake, season, and parameter. HINT: We will bring back our friends group_by and summarise for this.\n\n\nClick to see a solution\n\n\nwq_season_summary &lt;- wq %&gt;%\n    group_by(LocationName, season, Parameter) %&gt;%\n    summarise(mean = mean(Value, na.rm = TRUE), median = median(Value, na.rm = TRUE),\n        min = min(Value, na.rm = TRUE), max = max(Value, na.rm = TRUE), sd = sd(Value,\n            na.rm = TRUE), perc_95 = quantile(Value, 0.95))\n\n# Open up your dataframe and see if all looks good. There should be one value\n# for each season, lake, and parameter\n\n\n\n\n\n\nWe have a dataframe with the ranges of the NPSFM bands for each variable. We will need to read this in, merge together with our wq_summary dataframe, which has the annual median values for each variable. Then we will plot the data. But first we will have to do a little data manipulating…\n\n# read in bands\nbands &lt;- read.csv(\"./data/NPSFM_bands.csv\")\n# we want to join `bands` with the `wq` dataframe, but the column name for\n# `Parameter` is called `variable`. We will rename this so it matches with `wq`\n\nbands &lt;- bands %&gt;%\n    rename(Parameter = variable)\n\nThe values of TN and TP in bands$Parameter are in mg/m3, whereas in wq_summary they are in g/m3. We need to first convert TN and TP in wq_summary into mg/m3 before we can merge the two dataframes together.\n\nwq_summary &lt;- wq_summary %&gt;% \n  select(LocationName, Parameter, hydroyear, median) %&gt;% # select the columns we need\n  mutate(median = ifelse(Parameter %in% c('TN_gm3', 'TP_gm3'), median*1000, median),\n         Parameter = recode(Parameter, \n                            'TN_gm3' = 'TN_mgm3',\n                            'TP_gm3' = 'TP_mgm3'))\nprint(unique(wq_summary$Parameter))\n\n[1] \"TN_mgm3\"   \"TP_mgm3\"   \"chla_mgm3\" \"secchi_m\" \n\n\nNow that we have the columns in both of the dataframes wq_summary and bands set up properly, we can combine the two dataframes using the function left_join. This is another tidyverse function that merges two dataframes based on one or more common columns. It will keep all the rows from the first (left) dataframe and add any matching information in the second (right) dataframe. Here the matching columns is Parameter\n\nnof &lt;- left_join(wq_summary, bands, by = \"Parameter\")\n\nWarning in left_join(wq_summary, bands, by = \"Parameter\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 5 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nThis gives us a warning that there are “many-to-many relationships between x and y.” Sometimes this warning means that there is something wrong with your dataframe merge, but in this case, this is actually ok. It is telling us that in bands there are multiple matches for a single value of Parameter in wq_summary. That is because there are four values of bands$band (a, b, c, and d) which correspond to a single row in wq_summary. This has resulted in our new dataframe nof being much longer than the original wq_summary but that is expected behavior so we can ignore this warning.\nNow that we have our matching dataframe, we need to create maximum and minimum x values for which the color shading will be mapped onto our plot. These simply need to correspond to maximum and minimum years of our dataframe\n\nnof &lt;- nof %&gt;%\n    group_by(Parameter) %&gt;%\n    mutate(x_max = max(hydroyear), x_min = min(hydroyear))\n\nIf we look at nof again, we should have a minimum and maximum column for both x and y. We will use these in our plotting by adding a layer using geom_rect to map the colors of the different bands behind our points\n\nggplot(nof, aes(x = hydroyear, y = median, color = as.factor(LocationName))) + geom_rect(aes(xmin = x_min,\n    xmax = x_max, ymin = y_min, ymax = y_max, fill = band, alpha = 0.2), color = NA) +\n    geom_point(size = 2) + scale_fill_manual(values = c(\"#00A2E1FF\", \"#62BD19FF\",\n    \"#FFC726FF\", \"#FF671FFF\")) + facet_wrap(~Parameter, scales = \"free\") + labs(color = \"Site\") +\n    theme_bw() + theme(axis.text.x = element_text(angle = 75, hjust = 1)) + scale_y_log10()\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\n\n\nWarning: Removed 153 rows containing missing values or values outside the scale range\n(`geom_rect()`).\n\n\n\n\n\n\n\n\n\nChallenge 7: Secchi depth is not currently assessed as part of the NPSFM. Let’s remove it from our plot using the filter function:\n\n\nClick to see a solution\n\n\nnof %&gt;%\n    filter(Parameter != \"secchi_m\") %&gt;%\n    ggplot(aes(x = hydroyear, y = median, color = as.factor(LocationName))) + geom_rect(aes(xmin = x_min,\n    xmax = x_max, ymin = y_min, ymax = y_max, fill = band), color = NA) + geom_point(size = 2) +\n    scale_fill_manual(values = c(\"#00A2E1FF\", \"#62BD19FF\", \"#FFC726FF\", \"#FF671FFF\")) +\n    facet_wrap(~Parameter, scales = \"free\", nrow = 2) + labs(color = \"Site\") + theme_bw() +\n    theme(axis.text.x = element_text(angle = 75, hjust = 1)) + scale_y_log10()\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values."
  },
  {
    "objectID": "workshops/R_Tutorial_1_2025.html",
    "href": "workshops/R_Tutorial_1_2025.html",
    "title": "Lesson 1 - Fundamentals of R",
    "section": "",
    "text": "This introductory lesson is designed to teach you the fundamentals of using RStudio to analyze environmental data. First we will learn how to install packages.\n\n\nPackages provide new functions that can help us do specific actions in R. These will become increasingly useful as you learn more about R!\nThe main packages that we will use in this tutorial are:\n\ntidyverse\nreadxl\n\nBefore attempting to install these packages, make sure your Primary CRAN Repository is set to:\n\n“New Zealand [https] - University of Auckland”\n\nTo check this, click ‘Tools’ –&gt; ‘Global Options’ –&gt; ‘Packages’. Click ‘Change’ if you need to adjust this.\nYou can download most packages by clicking on the ‘Install’ button on the ‘packages’ tab in the lower right window pane. Then in the Install Packages popup, select ‘Repository (CRAN)’ from the ‘Install from’ drop box and type the name of the package you wish to download (e.g., dplyr).\nYou can also install packages directly using code.\n\ninstall.packages('tidyverse') # typically, R needs things to be in quotes, \n\npackage 'tidyverse' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\wwoelmer\\AppData\\Local\\Temp\\RtmpeYE7Yc\\downloaded_packages\n\n# either '' or \"\" if it is not a recognized object in the environment\ninstall.packages('readxl') \n\npackage 'readxl' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\wwoelmer\\AppData\\Local\\Temp\\RtmpeYE7Yc\\downloaded_packages\n\n\nOnce all of these packages are installed you can load them using the ‘library’ function:\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\nlibrary(readxl)\n\nWarning: package 'readxl' was built under R version 4.4.3\n\n\n\n\n\nOne of the main ways that you will interact with R is to create and re-use objects. Let’s just creating a few objects ourselves. We did this for an in-person workshop where we counted the number of participants and instructors. However, you can change the code whatever you like! If you’re alone, maybe try changing it to the number of doorknobs and windows in your room.\n\nnum_participants &lt;- 13# insert number of people in the room\n  \nnum_instructors &lt;- 3# insert number of instructors in the room\n  \nparticipant_instructor_ratio &lt;- num_participants/num_instructors\n\nVoila! You’ve created new objects! You should now see the objects in the upper right of your RStudio, in the Environment window.\n\n\n\nYou can read in many different file formats into R and each will use their own function (e.g., read.csv, read.table, read_excel). To read in a file, you need to tell R where the file is located, relative to your working directory. To check where R is looking for your files, we will run the following function:\n\ngetwd()\n\n[1] \"C:/Users/wwoelmer/OneDrive - The University of Waikato/Desktop/R_Workshops_Website/workshops\"\n\n\nThis function tells you where your working directory is located. Since we are using a project, it will be where you put your project on your computer. If you don’t use a project, you will need to set a working directory using setwd(). NOTE: I DO NOT recommend setting working directories for reproducibility reasons. Projects are the best way to organize your files. But see other resources about this if desired: https://rpubs.com/em_/wdInR\nNow let’s read in our water quality data\n\nwq &lt;- read.csv('./data/BoP_WQ_formatted.csv') # HINT: hit 'tab' as you're typin the directory to see a list of files in this directory\n\nThe ./ notation means: look in the working directory (that is what the period represents), then in the folder data, then look for a file called BoP_WQ_formatted.csv\nNow that we’ve read in our data, it’s best practice to look at it and see if everything looks alright.\n\nView(wq) # this opens up the dataframe to view, \n# you can also do this by clicking on your dataframe ('wq') in the Environment at right"
  },
  {
    "objectID": "workshops/R_Tutorial_1_2025.html#overview",
    "href": "workshops/R_Tutorial_1_2025.html#overview",
    "title": "Lesson 1 - Fundamentals of R",
    "section": "",
    "text": "This introductory lesson is designed to teach you the fundamentals of using RStudio to analyze environmental data. First we will learn how to install packages.\n\n\nPackages provide new functions that can help us do specific actions in R. These will become increasingly useful as you learn more about R!\nThe main packages that we will use in this tutorial are:\n\ntidyverse\nreadxl\n\nBefore attempting to install these packages, make sure your Primary CRAN Repository is set to:\n\n“New Zealand [https] - University of Auckland”\n\nTo check this, click ‘Tools’ –&gt; ‘Global Options’ –&gt; ‘Packages’. Click ‘Change’ if you need to adjust this.\nYou can download most packages by clicking on the ‘Install’ button on the ‘packages’ tab in the lower right window pane. Then in the Install Packages popup, select ‘Repository (CRAN)’ from the ‘Install from’ drop box and type the name of the package you wish to download (e.g., dplyr).\nYou can also install packages directly using code.\n\ninstall.packages('tidyverse') # typically, R needs things to be in quotes, \n\npackage 'tidyverse' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\wwoelmer\\AppData\\Local\\Temp\\RtmpeYE7Yc\\downloaded_packages\n\n# either '' or \"\" if it is not a recognized object in the environment\ninstall.packages('readxl') \n\npackage 'readxl' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\wwoelmer\\AppData\\Local\\Temp\\RtmpeYE7Yc\\downloaded_packages\n\n\nOnce all of these packages are installed you can load them using the ‘library’ function:\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\nlibrary(readxl)\n\nWarning: package 'readxl' was built under R version 4.4.3\n\n\n\n\n\nOne of the main ways that you will interact with R is to create and re-use objects. Let’s just creating a few objects ourselves. We did this for an in-person workshop where we counted the number of participants and instructors. However, you can change the code whatever you like! If you’re alone, maybe try changing it to the number of doorknobs and windows in your room.\n\nnum_participants &lt;- 13# insert number of people in the room\n  \nnum_instructors &lt;- 3# insert number of instructors in the room\n  \nparticipant_instructor_ratio &lt;- num_participants/num_instructors\n\nVoila! You’ve created new objects! You should now see the objects in the upper right of your RStudio, in the Environment window.\n\n\n\nYou can read in many different file formats into R and each will use their own function (e.g., read.csv, read.table, read_excel). To read in a file, you need to tell R where the file is located, relative to your working directory. To check where R is looking for your files, we will run the following function:\n\ngetwd()\n\n[1] \"C:/Users/wwoelmer/OneDrive - The University of Waikato/Desktop/R_Workshops_Website/workshops\"\n\n\nThis function tells you where your working directory is located. Since we are using a project, it will be where you put your project on your computer. If you don’t use a project, you will need to set a working directory using setwd(). NOTE: I DO NOT recommend setting working directories for reproducibility reasons. Projects are the best way to organize your files. But see other resources about this if desired: https://rpubs.com/em_/wdInR\nNow let’s read in our water quality data\n\nwq &lt;- read.csv('./data/BoP_WQ_formatted.csv') # HINT: hit 'tab' as you're typin the directory to see a list of files in this directory\n\nThe ./ notation means: look in the working directory (that is what the period represents), then in the folder data, then look for a file called BoP_WQ_formatted.csv\nNow that we’ve read in our data, it’s best practice to look at it and see if everything looks alright.\n\nView(wq) # this opens up the dataframe to view, \n# you can also do this by clicking on your dataframe ('wq') in the Environment at right"
  }
]